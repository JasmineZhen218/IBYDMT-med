{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "\n",
    "root_dir = \"../\"\n",
    "sys.path.append(root_dir)\n",
    "import configs\n",
    "import datasets\n",
    "import models\n",
    "from ibydmt import get_config, get_dataset, get_predictions, get_test_classes\n",
    "\n",
    "# from ibydmt.utils.config import get_config\n",
    "# from ibydmt.utils.data import get_dataset\n",
    "# from ibydmt.classifiers import get_predictions\n",
    "# from ibydmt.tester import get_test_classes\n",
    "\n",
    "config_name = \"chexpert\"\n",
    "config = get_config(config_name)\n",
    "\n",
    "dataset = get_dataset(config, train=False)\n",
    "label = [target for _, target in dataset.samples]\n",
    "classes = dataset.classes\n",
    "\n",
    "test_classes = get_test_classes(config)\n",
    "test_classes_idx = np.array([classes.index(c) for c in test_classes])\n",
    "\n",
    "backbone_configs = config.sweep([\"data.backbone\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: /tmp/biovil_t_image_model_proj_size_128.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cis/home/jteneggi/miniconda3/envs/cuda118/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'BertTokenizer'. \n",
      "The class this function is called from is 'CXRBertTokenizer'.\n",
      "You are using a model of type bert to instantiate a model of type cxr-bert. This is not supported for all configurations of models and can yield errors.\n",
      "Some weights of the model checkpoint at microsoft/BiomedVLP-BioViL-T were not used when initializing CXRBertModel: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing CXRBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing CXRBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cxr-bert-specialized:\n",
      "\t abnormal: 83.71%\n",
      "\t normal: 42.39%\n",
      "cxr-bert-specialized & $42.39\\%$ & $83.71\\%$\n",
      "Average: 63.05% pm 20.66%\n",
      "average & $42.39\\% \\pm 0.00\\%$ & $83.71\\% \\pm 0.00\\%$\n"
     ]
    }
   ],
   "source": [
    "accuracy = np.zeros((len(backbone_configs), len(test_classes)))\n",
    "\n",
    "for i, backbone_config in enumerate(backbone_configs):\n",
    "    df = get_predictions(backbone_config)\n",
    "\n",
    "    output = df.values[:, 1:]\n",
    "    prediction = np.argmax(output, axis=-1)\n",
    "    confusion_matrix = metrics.confusion_matrix(label, prediction, normalize=\"true\")\n",
    "    backbone_accuracy = np.diag(confusion_matrix)\n",
    "    backbone_accuracy = backbone_accuracy[test_classes_idx]\n",
    "\n",
    "    accuracy[i] = backbone_accuracy\n",
    "\n",
    "    print(f\"{backbone_config.data.backbone}:\")\n",
    "    sorted_class_idx = np.argsort(backbone_accuracy)[::-1]\n",
    "    sorted_class_names = [test_classes[idx] for idx in sorted_class_idx]\n",
    "    sorted_backbone_accuracy = backbone_accuracy[sorted_class_idx]\n",
    "    for class_name, class_accuracy in zip(sorted_class_names, sorted_backbone_accuracy):\n",
    "        print(f\"\\t {class_name}: {class_accuracy:.2%}\")\n",
    "\n",
    "    print(\n",
    "        f\"{backbone_config.data.backbone} & \"\n",
    "        + \" & \".join([f\"${a*100:.2f}\\\\%$\" for a in backbone_accuracy])\n",
    "    )\n",
    "    print(\n",
    "        f\"Average: {np.mean(backbone_accuracy):.2%} pm {np.std(backbone_accuracy):.2%}\"\n",
    "    )\n",
    "\n",
    "\n",
    "accuracy_mu = np.mean(accuracy, axis=0)\n",
    "accuracy_std = np.std(accuracy, axis=0)\n",
    "print(\n",
    "    \"average & \"\n",
    "    + \" & \".join(\n",
    "        [\n",
    "            f\"${mu*100:.2f}\\\\% \\pm {std*100:.2f}\\\\%$\"\n",
    "            for mu, std in zip(accuracy_mu, accuracy_std)\n",
    "        ]\n",
    "    )\n",
    ")\n",
    "# for class_name, mu, std in zip(test_classes, accuracy_mu, accuracy_std):\n",
    "#     print(f\"{class_name}: {mu:.2%} pm {std:.2%}\")\n",
    "# sorted_class_idx = np.argsort(accuracy_mu)[::-1][:k]\n",
    "# sorted_accuracy = accuracy_mu[sorted_class_idx]\n",
    "# sorted_std = accuracy_std[sorted_class_idx]\n",
    "# sorted_class_names = [test_classes[idx] for idx in sorted_class_idx]\n",
    "# print(f\"Top {k} classes:\")\n",
    "# for class_name, class_accuracy, class_std in zip(\n",
    "#     sorted_class_names, sorted_accuracy, sorted_std\n",
    "# ):\n",
    "#     print(f\"\\t {class_name}: {class_accuracy:.2%} pm {class_std:.2%}\")\n",
    "\n",
    "# test_classes_path = os.path.join(\n",
    "#     root_dir, \"results\", config.name.lower(), \"test_classes.txt\"\n",
    "# )\n",
    "# with open(test_classes_path, \"w\") as f:\n",
    "#     for class_name in sorted_class_names:\n",
    "#         f.write(f\"{class_name}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6304722187642641 0.2066216440516204\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(accuracy), np.std(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda118",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
