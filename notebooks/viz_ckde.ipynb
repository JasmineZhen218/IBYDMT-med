{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import numpy as np\n",
    "import ml_collections\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from torchvision.transforms import Compose, CenterCrop, ToTensor\n",
    "from torchvision.utils import make_grid\n",
    "\n",
    "root_dir = \"../\"\n",
    "sys.path.append(root_dir)\n",
    "import configs\n",
    "import datasets\n",
    "from ibydmt.utils.config import get_config\n",
    "from ibydmt.utils.concept_data import get_dataset_with_concepts\n",
    "from ibydmt.classifiers import ZeroShotClassifier\n",
    "from ibydmt.samplers import cKDE\n",
    "from models.clip_classifier import CLIPClassifier\n",
    "from notebooks.viz_ckde_utils import viz_cond_pdf, viz_local_dist\n",
    "\n",
    "config_name = \"imagenette\"\n",
    "config = get_config(config_name)\n",
    "\n",
    "ckde = ml_collections.ConfigDict()\n",
    "ckde.metric = config.ckde.metric\n",
    "ckde.scale_method = \"neff\"\n",
    "ckde.scale = 2000\n",
    "\n",
    "config.ckde = ckde\n",
    "\n",
    "transform = Compose([CenterCrop(224), ToTensor()])\n",
    "dataset = get_dataset_with_concepts(config, train=False)\n",
    "classes, concepts = dataset.classes, dataset.concepts\n",
    "\n",
    "model = cKDE(config)\n",
    "classifier = CLIPClassifier.load_or_train(config, root_dir)\n",
    "\n",
    "figure_dir = os.path.join(root_dir, \"figures\", config.name.lower(), \"ckde\")\n",
    "os.makedirs(figure_dir, exist_ok=True)\n",
    "\n",
    "sns.set_style(\"white\")\n",
    "sns.set_context(\"paper\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_idx = {\n",
    "    \"tench\": [330, 117],\n",
    "    \"English springer\": [715, 571],\n",
    "    \"cassette player\": [1041, 981],\n",
    "    \"chainsaw\": [1207, 1289],\n",
    "    \"church\": [1831, 1599],\n",
    "    \"French horn\": [2306, 2180],\n",
    "    \"garbage truck\": [2425, 2376],\n",
    "    \"gas pump\": [3016, 2889],\n",
    "    \"golf ball\": [3439, 3320],\n",
    "    \"parachute\": [3696, 3656],\n",
    "}\n",
    "\n",
    "Z = dataset.Z\n",
    "for class_name, idx in class_idx.items():\n",
    "    k = classes.index(class_name)\n",
    "\n",
    "    def _classifier(h):\n",
    "        return classifier(h)[:, k]\n",
    "\n",
    "    for _idx in idx:\n",
    "        idx_figure_dir = os.path.join(figure_dir, f\"{class_name}_{_idx}\")\n",
    "        os.makedirs(idx_figure_dir, exist_ok=True)\n",
    "\n",
    "        image, _, z, y = dataset[_idx]\n",
    "\n",
    "        _, ax = plt.subplots(figsize=(16 / 4, 9 / 4))\n",
    "        ax.imshow(image.permute(1, 2, 0))\n",
    "        ax.set_title(f\"Class: {class_name}\")\n",
    "        ax.axis(\"off\")\n",
    "        plt.savefig(\n",
    "            os.path.join(idx_figure_dir, f\"image_{model.scale}.pdf\"),\n",
    "            bbox_inches=\"tight\",\n",
    "        )\n",
    "        plt.savefig(\n",
    "            os.path.join(idx_figure_dir, f\"image_{model.scale}.png\"),\n",
    "            bbox_inches=\"tight\",\n",
    "        )\n",
    "        plt.show()\n",
    "\n",
    "        # viz_cond_pdf(model, z, class_name, concepts, idx_figure_dir)\n",
    "        viz_local_dist(model, _classifier, z, class_name, concepts, idx_figure_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entropy = np.zeros((len(classes), len(concepts)))\n",
    "\n",
    "for i, class_name in enumerate(classes):\n",
    "    for j, concept in enumerate(concepts):\n",
    "        _results = results[(class_name, concept)]\n",
    "\n",
    "        _entropy = []\n",
    "        for idx, nn_idx in _results.items():\n",
    "            unique, counts = np.unique(nn_idx, return_counts=True)\n",
    "            p = counts / np.sum(counts)\n",
    "            _entropy.append(-np.sum(p * np.log(p)))\n",
    "\n",
    "        entropy[i, j] = np.mean(_entropy)\n",
    "\n",
    "_, ax = plt.subplots(figsize=(16, 9 / 16 * len(classes)))\n",
    "sns.heatmap(\n",
    "    entropy, annot=True, fmt=\".2f\", ax=ax, xticklabels=concepts, yticklabels=classes\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_concepts_idx = np.argsort(entropy, axis=-1)\n",
    "\n",
    "for i, class_name in enumerate(classes):\n",
    "    class_idx = []\n",
    "    for concept in concepts:\n",
    "        class_idx.extend(list(results[(class_name, concept)].keys()))\n",
    "    class_idx = list(set(class_idx))\n",
    "\n",
    "    n, k, m = 5, 4, 4\n",
    "\n",
    "    idx = np.random.choice(class_idx, n, replace=False)\n",
    "    image = torch.stack([dataset[_idx][0] for _idx in idx])\n",
    "\n",
    "    top_k_concepts_idx = sorted_concepts_idx[i, -k:]\n",
    "    top_k_concepts = [concepts[j] for j in top_k_concepts_idx[::-1]]\n",
    "\n",
    "    _, axes = plt.subplots(\n",
    "        1,\n",
    "        k + 1,\n",
    "        figsize=(16, 9),\n",
    "        width_ratios=[1] + k * [m],\n",
    "        gridspec_kw={\"wspace\": 0.05},\n",
    "    )\n",
    "    ax = axes[0]\n",
    "    im = make_grid(image, nrow=1)\n",
    "    ax.imshow(im.permute(1, 2, 0))\n",
    "    ax.axis(\"off\")\n",
    "    ax.set_title(f\"{class_name}\")\n",
    "\n",
    "    for j, concept in enumerate(top_k_concepts):\n",
    "        nn = torch.zeros(n * m, 3, 128, 128)\n",
    "        for i, _idx in enumerate(idx):\n",
    "            nn_idx = results[(class_name, concept)][_idx]\n",
    "            nn_idx = np.unique(nn_idx)\n",
    "            nn_idx = np.random.choice(nn_idx, m, replace=True)\n",
    "\n",
    "            for p, nn_idx in enumerate(nn_idx):\n",
    "                nn[i * m + p] = model.dataset[nn_idx][0]\n",
    "\n",
    "        ax = axes[j + 1]\n",
    "        im = make_grid(nn, nrow=m)\n",
    "        ax.imshow(im.permute(1, 2, 0))\n",
    "        ax.axis(\"off\")\n",
    "        ax.set_title(concept)\n",
    "\n",
    "    figure_path = os.path.join(figure_dir, f\"{class_name}_{concept_name}\")\n",
    "    plt.savefig(f\"{figure_path}.pdf\", bbox_inches=\"tight\")\n",
    "    plt.savefig(f\"{figure_path}.png\", bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda118",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
