{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from torchvision.utils import make_grid\n",
    "from torchvision.transforms import Compose, CenterCrop, ToTensor\n",
    "from functools import reduce\n",
    "from scipy.special import softmax\n",
    "\n",
    "root_dir = \"../\"\n",
    "sys.path.append(root_dir)\n",
    "from configs.utils import get_config\n",
    "from concept_datasets import get_concept_dataset\n",
    "from models.clip_classifier import CLIPClassifier\n",
    "\n",
    "config_name = \"imagenette\"\n",
    "config = get_config(config_name)\n",
    "\n",
    "results_dir = os.path.join(root_dir, \"results\", config.name.lower())\n",
    "\n",
    "transform = Compose([CenterCrop(224), ToTensor()])\n",
    "train_dataset = dataset = get_concept_dataset(\n",
    "    config, train=True, transform=transform, return_image=True\n",
    ")\n",
    "val_dataset = get_concept_dataset(config, train=False, return_image=True)\n",
    "print(f\"Train images: {len(train_dataset)}\")\n",
    "print(f\"Validation images: {len(val_dataset)}\")\n",
    "print(f\"Total images: {len(train_dataset) + len(val_dataset)}\")\n",
    "classes, concepts = dataset.classes, dataset.concepts\n",
    "\n",
    "classifier = CLIPClassifier.load_or_train(config, root_dir)\n",
    "classifier.predict(root_dir)\n",
    "\n",
    "figure_dir = os.path.join(root_dir, \"figures\", config.name.lower(), \"images\")\n",
    "os.makedirs(figure_dir, exist_ok=True)\n",
    "\n",
    "sns.set_style(\"white\")\n",
    "sns.set_context(\"paper\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_idx = {\n",
    "    class_name: [idx for idx, y in enumerate(dataset.Y) if y == i]\n",
    "    for i, class_name in enumerate(classes)\n",
    "}\n",
    "image_idx = {\n",
    "    class_name: np.random.choice(idx, 5).tolist()\n",
    "    for class_name, idx in class_idx.items()\n",
    "}\n",
    "\n",
    "_, axes = plt.subplots(1, len(classes), figsize=(16, 9), gridspec_kw={\"wspace\": 0.1})\n",
    "for i, (class_name, idx) in enumerate(image_idx.items()):\n",
    "    images = torch.stack([dataset[_idx][0] for _idx in idx])\n",
    "\n",
    "    ax = axes[i]\n",
    "    img = make_grid(images, nrow=1)\n",
    "    ax.imshow(img.permute(1, 2, 0))\n",
    "    ax.axis(\"off\")\n",
    "    ax.set_title(class_name)\n",
    "\n",
    "plt.savefig(os.path.join(figure_dir, \"sample_images.pdf\"), bbox_inches=\"tight\")\n",
    "plt.savefig(os.path.join(figure_dir, \"sample_images.png\"), bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_image_idx = reduce(lambda x, y: x + y, list(image_idx.values()))\n",
    "\n",
    "for i, idx in enumerate(_image_idx):\n",
    "    image, h, z, label = dataset[idx]\n",
    "    class_name = dataset.classes[label]\n",
    "\n",
    "    output = classifier(h)\n",
    "    probs = softmax(output / 0.1)\n",
    "\n",
    "    sorted_idx = np.argsort(z)[::-1]\n",
    "    sorted_z = z[sorted_idx]\n",
    "    sorted_concepts = [concepts[i] for i in sorted_idx]\n",
    "\n",
    "    _, axes = plt.subplots(1, 2, figsize=(9 / 2, 16 / 4), gridspec_kw={\"wspace\": 0.7})\n",
    "    ax = axes[0]\n",
    "    ax.imshow(image.permute(1, 2, 0))\n",
    "    ax.axis(\"off\")\n",
    "    ax.set_title(class_name)\n",
    "\n",
    "    ax = axes[1]\n",
    "    sns.barplot(x=sorted_z, y=sorted_concepts, ax=ax)\n",
    "    ax.set_xlabel(r\"$z$\")\n",
    "    ax.set_xlim(0.8 * sorted_z.min())\n",
    "\n",
    "    # ax = axes[2]\n",
    "    # sns.barplot(x=probs, y=dataset.classes, ax=ax)\n",
    "\n",
    "    plt.savefig(os.path.join(figure_dir, f\"{class_name}_{i}.pdf\"), bbox_inches=\"tight\")\n",
    "    plt.savefig(os.path.join(figure_dir, f\"{class_name}_{i}.png\"), bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = get_predictions(config, root_dir)\n",
    "predictions[\"correct\"] = predictions[\"class\"] == predictions[\"prediction\"]\n",
    "\n",
    "class_correct = predictions.groupby(\"class\")[\"correct\"]\n",
    "class_accuracy = class_correct.mean().reset_index()\n",
    "class_std = class_correct.std().reset_index()\n",
    "\n",
    "sorted_idx = np.argsort(class_accuracy[\"correct\"].values)[::-1]\n",
    "sorted_classes = class_accuracy[\"class\"].values[sorted_idx]\n",
    "sorted_accuracy = class_accuracy[\"correct\"].values[sorted_idx]\n",
    "sorted_std = class_std[\"correct\"].values[sorted_idx]\n",
    "\n",
    "_, ax = plt.subplots(figsize=(16 / 4, 9 / 4))\n",
    "sns.barplot(x=sorted_accuracy, y=sorted_classes, ax=ax)\n",
    "ax.set_xlabel(\"Accuracy\")\n",
    "ax.set_xlim(0.8 * sorted_accuracy.min(), 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda118",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
