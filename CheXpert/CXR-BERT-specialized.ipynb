{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CXR-BERT-specialized\n",
    "CXR-BERT is a chest X-ray (CXR) domain-specific language model that makes use of an improved vocabulary, novel pretraining procedure, weight regularization, and text augmentations. The resulting model demonstrates improved performance on radiology natural language inference, radiology masked language model token prediction, and downstream vision-language processing tasks such as zero-shot phrase grounding and image classification.\n",
    "\n",
    "First, we pretrain CXR-BERT-general from a randomly initialized BERT model via Masked Language Modeling (MLM) on abstracts PubMed and clinical notes from the publicly-available MIMIC-III and MIMIC-CXR. In that regard, the general model is expected be applicable for research in clinical domains other than the chest radiology through domain specific fine-tuning.\n",
    "\n",
    "CXR-BERT-specialized is continually pretrained from CXR-BERT-general to further specialize in the chest X-ray domain. At the final stage, CXR-BERT is trained in a multi-modal contrastive learning framework, similar to the CLIP framework. The latent representation of [CLS] token is utilized to align text/image embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cis/home/zwang/IBYDMT-med/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "# Load the model and tokenizer\n",
    "url = \"microsoft/BiomedVLP-CXR-BERT-specialized\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(url, trust_remote_code=True)\n",
    "model = AutoModel.from_pretrained(url, trust_remote_code=True)\n",
    "\n",
    "# Input text prompts (e.g., reference, synonym, contradiction)\n",
    "text_prompts = [\"There is no pneumothorax or pleural effusion\",\n",
    "                \"No pleural effusion or pneumothorax is seen\",\n",
    "                \"The extent of the pleural effusion is constant.\"]\n",
    "\n",
    "# Tokenize and compute the sentence embeddings\n",
    "tokenizer_output = tokenizer.batch_encode_plus(batch_text_or_text_pairs=text_prompts,\n",
    "                                               add_special_tokens=True,\n",
    "                                               padding='longest',\n",
    "                                               return_tensors='pt')\n",
    "embeddings = model.get_projected_text_embeddings(input_ids=tokenizer_output.input_ids,\n",
    "                                                 attention_mask=tokenizer_output.attention_mask)\n",
    "\n",
    "# Compute the cosine similarity of sentence embeddings obtained from input text prompts.\n",
    "sim = torch.mm(embeddings, embeddings.t())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoConfig\n",
    "\n",
    "config = AutoConfig.from_pretrained(\"microsoft/BiomedVLP-CXR-BERT-specialized\")\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
